{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import timeit\n",
    "from pandas import to_datetime, date_range\n",
    "import wrf, xarray, sys\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### define paths\n",
    "\n",
    "dataPath = '/glade/scratch/doubrawa/final_data/les/'\n",
    "outPath  = '/glade/scratch/doubrawa/post_processing/'\n",
    "\n",
    "### define some parameters\n",
    "\n",
    "n_processors       = 1800\n",
    "domainId           = 4\n",
    "prefix             = \"LES_25m\" if domainId==4 else \"LES_100m\"\n",
    "\n",
    "### horizontal size of staggered and non-staggered grids\n",
    "\n",
    "n_east_west        = 1200\n",
    "n_east_west_stag   = n_east_west + 1\n",
    "n_south_north      = 1200\n",
    "n_south_north_stag = n_south_north + 1\n",
    "\n",
    "### variables of interest, and how they will be called in the wrfout file\n",
    "\n",
    "xarray_mapping = {\"w\":\"wa\",\"u\":\"U\",\"v\":\"V\",\"theta\":\"theta\"}\n",
    "units = {\"w\":\"m s-1\",\"u\":\"m s-1\",\"v\":\"m s-1\",\"theta\":\"K\"}\n",
    "names = {\"w\":\"vertical velocity\",\"u\":\"zonal velocity\",\"v\":\"meridional velocity\",\"theta\":\"potential temperature\"}   \n",
    "\n",
    "## total desired variables \n",
    "\n",
    "variables_static = [\"XLAT\",\"XLONG\",\"ter\"]\n",
    "variables_2d     = [\"RMOL\",\"HFX\",\"UST\",\"LH\",\"QFX\"]\n",
    "variables_3d     = [\"U\",\"V\",\"wa\",\"theta\",\"z\"]\n",
    "variables        = variables_2d + variables_3d   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what day to focus on\n",
    "day  = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_16UTC/wrfout_d04_2015-03-21_16:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_17:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_17:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_17:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_17UTC/wrfout_d04_2015-03-21_17:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_18:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_18:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_18:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_18UTC/wrfout_d04_2015-03-21_18:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_19:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_19:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_19:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_19UTC/wrfout_d04_2015-03-21_19:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_20:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_20:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_20:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_20UTC/wrfout_d04_2015-03-21_20:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_21:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_21:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_21:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_21UTC/wrfout_d04_2015-03-21_21:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_22:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_22:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_22:00.nc\n",
      "----------------------\n",
      "/glade/scratch/doubrawa/final_data/les/032115/032115_22UTC/wrfout_d04_2015-03-21_22:30:10_1799/glade/scratch/doubrawa/post_processing/LES_25m_SPATIAL_AVERAGED_PROFILES_2015-03-21_23:00:00.csv\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_100.0_m_AGL_2015-03-21_23:00.nc\n",
      "w\n",
      "u\n",
      "v\n",
      "theta\n",
      "Saving : WRF_LES_25m_500.0_m_AGL_2015-03-21_23:00.nc\n"
     ]
    }
   ],
   "source": [
    "# loop through all hours!\n",
    "for hour in range(17,24,1):\n",
    "    \n",
    "    desired_times = pd.date_range(start='2015-03-{1:d} {0:d}:00'.format(hour,day),end='2015-03-{1:d} {0:d}:05'.format(hour,day), freq='10min')\n",
    "\n",
    "    # find out how many history files there are per processor in this folder\n",
    "    file_paths = sorted(glob.glob(os.path.join(dataPath,\n",
    "                 \"03{0:d}15\".format(day,hour),\n",
    "                 \"03{0:d}15_{1:d}UTC\".format(day,hour),\n",
    "                 'wrfout_d0{0}*_0000'.format(domainId))))\n",
    "    \n",
    "    if day==21:\n",
    "        # when the hour 00 is requested for march 21 (simulation from first batch of domingo's runs), then we need to grab the 00 time from the file of the previous half hour\n",
    "        file_paths_hour_before = sorted(glob.glob(os.path.join(dataPath,\n",
    "                                \"03{0:d}15\".format(day,hour-1),\n",
    "                                \"03{0:d}15_{1:d}UTC\".format(day,hour-1),\n",
    "                                'wrfout_d0{0}*_0000'.format(domainId))))\n",
    "        [file_paths.append(f) for f in file_paths_hour_before]\n",
    "\n",
    "    # for each desired timestamp, find out which ncfile to open\n",
    "    map_desired_time_to_ncfile = {}\n",
    "    for file_path in file_paths:\n",
    "        wrfnc = xarray.open_dataset(file_path)\n",
    "        wrf_datetimes = np.asarray([ to_datetime(ii) for ii in wrfnc.XTIME.data ])    \n",
    "        for desired_time in desired_times:\n",
    "            if desired_time in wrf_datetimes:\n",
    "                map_desired_time_to_ncfile[desired_time] = file_path\n",
    "\n",
    "\n",
    "    # only once every time we run this code, we will need to read in the static files\n",
    "    data_static = {}\n",
    "    for var in variables_static:\n",
    "        data_static[var] = np.zeros((n_south_north,n_east_west))                \n",
    "\n",
    "    first = True\n",
    "\n",
    "    for desired_time in map_desired_time_to_ncfile.keys():\n",
    "\n",
    "        print('----------------------')\n",
    "        file_prefix = map_desired_time_to_ncfile[desired_time][0:-4]\n",
    "\n",
    "        # for this time, allocate space\n",
    "        data         = {}\n",
    "        for var in [\"U\"]:\n",
    "            data[var] = np.zeros((72,n_south_north,n_east_west_stag))\n",
    "        for var in [\"V\"]:\n",
    "            data[var] = np.zeros((72,n_south_north_stag,n_east_west))    \n",
    "        for var in variables_2d:\n",
    "            data[var] = np.zeros((n_south_north,n_east_west))\n",
    "        for var in [\"wa\",\"theta\",\"z\"]:\n",
    "            data[var] = np.zeros((72,n_south_north,n_east_west))           \n",
    "\n",
    "        for processor in range(n_processors):\n",
    "\n",
    "            file_name = glob.glob(file_prefix+\"{0:04d}\".format(processor))[0]\n",
    "\n",
    "            # print out which file is being read\n",
    "            sys.stdout.write('\\r'+file_name) \n",
    "\n",
    "            # open the netcdf file with xarray\n",
    "            wrfnc = xarray.open_dataset(file_name)\n",
    "            wrf_datetimes = np.asarray([ to_datetime(ii) for ii in wrfnc.XTIME.data ])\n",
    "\n",
    "            # open it in a different way also to use the wrf package\n",
    "            wrfnc_for_wrf = Dataset(file_name,'r')              \n",
    "\n",
    "            # find out what index corresponds to the desired time\n",
    "            if processor==0:\n",
    "                dt_between_desired_and_actual = np.min([ ii.seconds for ii in (wrf_datetimes - desired_time) ])\n",
    "                dt_idx = np.argmin([ ii.seconds for ii in (wrf_datetimes - desired_time) ])\n",
    "\n",
    "            # for this time and this processor, get all the variables:\n",
    "            for var in variables:\n",
    "\n",
    "                try:\n",
    "                    data_tmp = wrf.getvar(wrfnc_for_wrf, var, timeidx=dt_idx).data\n",
    "                except:\n",
    "                    data_tmp = wrfnc[var].isel(Time=dt_idx).data       \n",
    "\n",
    "                we_0 = getattr(wrfnc,'WEST-EAST_PATCH_START_UNSTAG') - 1        \n",
    "                we_1 = getattr(wrfnc,'WEST-EAST_PATCH_END_UNSTAG')                \n",
    "\n",
    "                sn_0 = getattr(wrfnc,'SOUTH-NORTH_PATCH_START_UNSTAG') - 1       \n",
    "                sn_1 = getattr(wrfnc,'SOUTH-NORTH_PATCH_END_UNSTAG')               \n",
    "\n",
    "                if data_tmp.ndim==3:\n",
    "                    if var=='U':\n",
    "                        we_0 = getattr(wrfnc,'WEST-EAST_PATCH_START_STAG') - 1        \n",
    "                        we_1 = getattr(wrfnc,'WEST-EAST_PATCH_END_STAG')                                \n",
    "                    if var=='V':\n",
    "                        sn_0 = getattr(wrfnc,'SOUTH-NORTH_PATCH_START_STAG') - 1       \n",
    "                        sn_1 = getattr(wrfnc,'SOUTH-NORTH_PATCH_END_STAG')                                                                       \n",
    "                    data[var][:, sn_0:sn_1, we_0:we_1] = data_tmp.copy()\n",
    "                else:\n",
    "                    data[var][sn_0:sn_1, we_0:we_1] = data_tmp.copy()            \n",
    "\n",
    "            # only once every time we run this code, we will need to read in the static files\n",
    "            if first:\n",
    "                for var in variables_static:\n",
    "\n",
    "                    try:\n",
    "                        data_tmp = wrf.getvar(wrfnc_for_wrf, var, timeidx=dt_idx).data\n",
    "                    except:\n",
    "                        data_tmp = wrfnc[var].isel(Time=dt_idx).data       \n",
    "\n",
    "                    we_0 = getattr(wrfnc,'WEST-EAST_PATCH_START_UNSTAG') - 1        \n",
    "                    we_1 = getattr(wrfnc,'WEST-EAST_PATCH_END_UNSTAG')                \n",
    "\n",
    "                    sn_0 = getattr(wrfnc,'SOUTH-NORTH_PATCH_START_UNSTAG') - 1       \n",
    "                    sn_1 = getattr(wrfnc,'SOUTH-NORTH_PATCH_END_UNSTAG')               \n",
    "\n",
    "                    data_static[var][sn_0:sn_1, we_0:we_1] = data_tmp.copy()             \n",
    "\n",
    "        # remove terrain from z\n",
    "        data[\"z\"] = data[\"z\"] - data_static[\"ter\"]        \n",
    "\n",
    "        # unstagger u and v\n",
    "        data[\"U\"] = 0.5*(data[\"U\"][:,:,0:n_east_west_stag-1] + data[\"U\"][:,:,1:n_east_west_stag+1])\n",
    "        data[\"V\"] = 0.5*(data[\"V\"][:,0:n_south_north_stag-1,:] + data[\"V\"][:,1:n_south_north_stag+1,:])\n",
    "\n",
    "        # get profile of planar averages\n",
    "        data_mean = {}\n",
    "        for var in [\"U\",\"V\",\"wa\",\"theta\",\"z\"]:\n",
    "            data_mean[var] = np.mean(data[var],axis=(1,2))\n",
    "\n",
    "        # get profile of planar perturbations\n",
    "        data_prime  = {}\n",
    "        for var in data_mean.keys():\n",
    "            data_prime[var] = data[var] - data_mean[var][:,None,None]   \n",
    "\n",
    "        # compute fluxes\n",
    "        fluxes = [\"U_U\",\"V_V\",\"wa_wa\",\"U_wa\",\"V_wa\",\"U_V\",\"wa_theta\"]\n",
    "        data_fluxes = {}\n",
    "        for flux in fluxes:\n",
    "            var1 = flux.split(\"_\")[0]\n",
    "            var2 = flux.split(\"_\")[1]\n",
    "            data_fluxes[flux] = np.mean(data_prime[var1]*data_prime[var2],axis=(1,2))        \n",
    "\n",
    "        # organize fluxes into a dataframe and save to csv file\n",
    "        df  = pd.DataFrame(data_mean).set_index(\"z\")\n",
    "        df[\"z_std_xy\"] = np.std(data[\"z\"],axis=(1,2))\n",
    "        df2 = pd.DataFrame(data_fluxes).set_index(df.index)\n",
    "        df  = pd.concat([df,df2],axis=1)\n",
    "        column_mapping = {\"U\":\"u\",\n",
    "         \"V\":\"v\",\n",
    "         \"wa\":\"w\",\n",
    "         \"theta\":\"theta\",\n",
    "         \"z_std_xy\":\"z_std_xy\",\n",
    "         \"U_U\":\"u_u\",\n",
    "         \"V_V\":\"v_v\",\n",
    "         \"wa_wa\":\"w_w\",\n",
    "         \"U_wa\":\"u_w\",\n",
    "         \"V_wa\":\"v_w\",\n",
    "         \"U_V\":\"u_v\",\n",
    "         \"wa_theta\":\"w_theta\",\n",
    "         \"wa_theta0\":\"w_theta0\"}\n",
    "        df.columns = [ column_mapping[col_old] for col_old in df.columns ]\n",
    "        fName = os.path.join(outPath,\"{0}_SPATIAL_AVERAGED_PROFILES_{1:%Y-%m-%d_%H:%M:%S}.csv\".format(prefix,desired_time))\n",
    "        print(fName)\n",
    "        df.to_csv(fName)      \n",
    "\n",
    "        # Save planar averages of two-dimensional quantities\n",
    "        means_2d = {}\n",
    "        for var in [\"RMOL\",\"HFX\"]:\n",
    "            means_2d[var] = np.mean(data[var])\n",
    "        a = pd.Series(means_2d)\n",
    "        fName = os.path.join(outPath,\"WRF_{0}_SPATIAL_AVERAGED_2D_{1:%Y-%m-%d_%H:%M:%S}.csv\".format(prefix,desired_time))   \n",
    "        a.to_csv(fName)\n",
    "\n",
    "        # Prepare planes of XLAT, XLONG\n",
    "        #\n",
    "        if first:\n",
    "            n_sn, n_we = data_static['XLAT'].shape\n",
    "            xlat = xarray.DataArray(data_static['XLAT'], \n",
    "                             coords={\"south_north\":range(n_sn),\"west_east\":range(n_we)}, \n",
    "                             dims=(\"south_north\",\"west_east\"), \n",
    "                             name=\"2-d latitude\", \n",
    "                             attrs={\"unit\":\"deg\",\"stagger\":\"\"})\n",
    "\n",
    "            xlong = xarray.DataArray(data_static['XLONG'], \n",
    "                             coords={\"south_north\":range(n_sn),\"west_east\":range(n_we)}, \n",
    "                             dims=(\"south_north\",\"west_east\"), \n",
    "                             name=\"2-d longitude\", \n",
    "                             attrs={\"unit\":\"deg\",\"stagger\":\"\"})\n",
    "        first = False\n",
    "\n",
    "        # Prepare z plane for vertical interpolation of 3-dimensional variables\n",
    "        #            \n",
    "        xarray_zref = xarray.DataArray(data[\"z\"], \\\n",
    "                                       coords={\"bottom_top\":range(72),\"south_north\":range(n_sn),\"west_east\":range(n_we)},  \\\n",
    "                                       dims=(\"bottom_top\",\"south_north\",\"west_east\"), \\\n",
    "                                       name=\"height above ground\", \\\n",
    "                                       attrs={\"unit\":\"m\",\"stagger\":\"\"})\n",
    "\n",
    "        xarray_zref[\"lat\"] = xlat\n",
    "        xarray_zref[\"lon\"] = xlong           \n",
    "\n",
    "\n",
    "        #\n",
    "        # Interpolate 3-dimensional variables to desired heights\n",
    "        #\n",
    "        heights = [100.0,500.0]            \n",
    "        for height in heights:\n",
    "            xarray_dict = {}         \n",
    "            for xarray_varname in [\"w\",\"u\",\"v\",\"theta\"]:\n",
    "                print(xarray_varname)\n",
    "                xarray_3d = xarray.DataArray(data[xarray_mapping[xarray_varname]][None,:,:,:],     \\\n",
    "                                               coords={  \"time\":[wrf_datetimes[dt_idx]],\"bottom_top\":range(72),\"south_north\":range(n_sn),\"west_east\":range(n_we)}, \\\n",
    "                                               dims=(\"time\",\"bottom_top\",\"south_north\",\"west_east\"), \n",
    "                                               name=names[xarray_varname],\n",
    "                                               attrs={\"unit\":units[xarray_varname],\"stagger\":\"\",\"height [m]\":height})\n",
    "\n",
    "                xarray_3d[\"lat\"] = xlat\n",
    "                xarray_3d[\"lon\"] = xlong\n",
    "\n",
    "                var_3d_now = data[xarray_mapping[xarray_varname]]\n",
    "                xarray_dict[xarray_varname] = wrf.interplevel(xarray_3d, xarray_zref, height, meta=True)\n",
    "                xarray_dict[xarray_varname][\"z\"] = height\n",
    "            dataset = xarray.Dataset(xarray_dict)\n",
    "            fName   = \"WRF_{0}_{1}_m_AGL_{2:%Y-%m-%d_%H:%M}.nc\".format(prefix,height,wrf_datetimes[dt_idx])\n",
    "            fPath   = os.path.join(outPath,fName)\n",
    "            print (\"Saving : {0}\".format(fName))\n",
    "            dataset.to_netcdf(fPath)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mwrfenv)",
   "language": "python",
   "name": "wrfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
